{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92db7460-a043-45ac-9e14-af33e41698a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9140c08d-fb6b-4ced-a79e-25172f598ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cv2_base_dir = os.path.dirname(os.path.abspath(cv2.__file__))\n",
    "haar_model = os.path.join(cv2_base_dir, 'data/haarcascade_frontalface_default.xml')\n",
    "face_classifier = cv2.CascadeClassifier(haar_model)\n",
    "cap = cv2.VideoCapture(0)\n",
    "id = 1\n",
    "name = \"Bharat\"\n",
    "img_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame from webcam.\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = frame[y:y+h, x:x+w]\n",
    "    img_id += 1\n",
    "    face = cv2.resize(cropped_face, (150, 150))\n",
    "    gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "    file_name_path = f\"DataSet/{name}\" + \".\" + str(id) + \".\"+ str(img_id) + \".jpg\"\n",
    "    cv2.imwrite(file_name_path, face)\n",
    "    cv2.putText(face, str(img_id), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Cropped Face\", face)\n",
    "    if cv2.waitKey(1) == ord('q') or int(img_id) == 100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f5d491a-82bf-4002-ac2a-4bfb1d5b32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label(image_name):\n",
    "    name = image_name.split('.')[-3]\n",
    "    if name == \"Bharat\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name == \"Shyam\":\n",
    "        return np.array([0,1,0])\n",
    "    elif name == \"Khedup\":\n",
    "        return np.array([0,0,1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "019e07a2-df2c-40ee-84d7-04f391c9506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data= []\n",
    "    for img in tqdm(os.listdir(\"DataSet\")):\n",
    "        path = os.path.join(\"DataSet\", img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50, 50))\n",
    "        data.append([np.array(img_data), my_label(img)])\n",
    "    shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3cd79c7-0f18-4944-8abf-88e7c78b3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 193.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[70]\n",
      "   [72]\n",
      "   [70]\n",
      "   ...\n",
      "   [87]\n",
      "   [87]\n",
      "   [88]]\n",
      "\n",
      "  [[69]\n",
      "   [69]\n",
      "   [69]\n",
      "   ...\n",
      "   [88]\n",
      "   [88]\n",
      "   [89]]\n",
      "\n",
      "  [[69]\n",
      "   [69]\n",
      "   [70]\n",
      "   ...\n",
      "   [90]\n",
      "   [88]\n",
      "   [92]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[49]\n",
      "   [49]\n",
      "   [50]\n",
      "   ...\n",
      "   [69]\n",
      "   [70]\n",
      "   [69]]\n",
      "\n",
      "  [[47]\n",
      "   [48]\n",
      "   [49]\n",
      "   ...\n",
      "   [70]\n",
      "   [70]\n",
      "   [68]]\n",
      "\n",
      "  [[49]\n",
      "   [50]\n",
      "   [48]\n",
      "   ...\n",
      "   [71]\n",
      "   [69]\n",
      "   [71]]]\n",
      "\n",
      "\n",
      " [[[67]\n",
      "   [68]\n",
      "   [67]\n",
      "   ...\n",
      "   [83]\n",
      "   [82]\n",
      "   [84]]\n",
      "\n",
      "  [[69]\n",
      "   [66]\n",
      "   [69]\n",
      "   ...\n",
      "   [85]\n",
      "   [86]\n",
      "   [87]]\n",
      "\n",
      "  [[70]\n",
      "   [70]\n",
      "   [67]\n",
      "   ...\n",
      "   [85]\n",
      "   [85]\n",
      "   [88]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[44]\n",
      "   [43]\n",
      "   [43]\n",
      "   ...\n",
      "   [18]\n",
      "   [63]\n",
      "   [67]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [22]\n",
      "   [66]\n",
      "   [66]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [31]\n",
      "   [62]\n",
      "   [68]]]\n",
      "\n",
      "\n",
      " [[[67]\n",
      "   [68]\n",
      "   [67]\n",
      "   ...\n",
      "   [83]\n",
      "   [82]\n",
      "   [84]]\n",
      "\n",
      "  [[69]\n",
      "   [66]\n",
      "   [69]\n",
      "   ...\n",
      "   [85]\n",
      "   [86]\n",
      "   [87]]\n",
      "\n",
      "  [[70]\n",
      "   [70]\n",
      "   [67]\n",
      "   ...\n",
      "   [85]\n",
      "   [85]\n",
      "   [88]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[44]\n",
      "   [43]\n",
      "   [43]\n",
      "   ...\n",
      "   [18]\n",
      "   [63]\n",
      "   [67]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [22]\n",
      "   [66]\n",
      "   [66]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [31]\n",
      "   [62]\n",
      "   [68]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[70]\n",
      "   [71]\n",
      "   [71]\n",
      "   ...\n",
      "   [86]\n",
      "   [87]\n",
      "   [89]]\n",
      "\n",
      "  [[71]\n",
      "   [71]\n",
      "   [70]\n",
      "   ...\n",
      "   [88]\n",
      "   [89]\n",
      "   [89]]\n",
      "\n",
      "  [[73]\n",
      "   [74]\n",
      "   [67]\n",
      "   ...\n",
      "   [87]\n",
      "   [89]\n",
      "   [91]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[19]\n",
      "   [19]\n",
      "   [19]\n",
      "   ...\n",
      "   [65]\n",
      "   [37]\n",
      "   [57]]\n",
      "\n",
      "  [[36]\n",
      "   [17]\n",
      "   [16]\n",
      "   ...\n",
      "   [67]\n",
      "   [67]\n",
      "   [67]]\n",
      "\n",
      "  [[48]\n",
      "   [35]\n",
      "   [13]\n",
      "   ...\n",
      "   [69]\n",
      "   [68]\n",
      "   [68]]]\n",
      "\n",
      "\n",
      " [[[67]\n",
      "   [68]\n",
      "   [67]\n",
      "   ...\n",
      "   [83]\n",
      "   [82]\n",
      "   [84]]\n",
      "\n",
      "  [[69]\n",
      "   [66]\n",
      "   [69]\n",
      "   ...\n",
      "   [85]\n",
      "   [86]\n",
      "   [87]]\n",
      "\n",
      "  [[70]\n",
      "   [70]\n",
      "   [67]\n",
      "   ...\n",
      "   [85]\n",
      "   [85]\n",
      "   [88]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[44]\n",
      "   [43]\n",
      "   [43]\n",
      "   ...\n",
      "   [18]\n",
      "   [63]\n",
      "   [67]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [22]\n",
      "   [66]\n",
      "   [66]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [31]\n",
      "   [62]\n",
      "   [68]]]\n",
      "\n",
      "\n",
      " [[[67]\n",
      "   [68]\n",
      "   [67]\n",
      "   ...\n",
      "   [83]\n",
      "   [82]\n",
      "   [84]]\n",
      "\n",
      "  [[69]\n",
      "   [66]\n",
      "   [69]\n",
      "   ...\n",
      "   [85]\n",
      "   [86]\n",
      "   [87]]\n",
      "\n",
      "  [[70]\n",
      "   [70]\n",
      "   [67]\n",
      "   ...\n",
      "   [85]\n",
      "   [85]\n",
      "   [88]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[44]\n",
      "   [43]\n",
      "   [43]\n",
      "   ...\n",
      "   [18]\n",
      "   [63]\n",
      "   [67]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [22]\n",
      "   [66]\n",
      "   [66]]\n",
      "\n",
      "  [[44]\n",
      "   [44]\n",
      "   [44]\n",
      "   ...\n",
      "   [31]\n",
      "   [62]\n",
      "   [68]]]]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = my_data()\n",
    "train = data[:240]\n",
    "test = data[240:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)\n",
    "X_test = np.array([i[1] for i in train])\n",
    "y_train = np.array([i[0] for i in train]).reshape(-1, 50, 50, 1)\n",
    "y_test = np.array([i[1] for i in train])\n",
    "\n",
    "print(X_train)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcc7677c-95a0-48c0-bf4e-e49dbfa052ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "from PIL import Image as pil\n",
    "from pkg_resources import parse_version\n",
    "\n",
    "if parse_version(pil.__version__)>=parse_version('10.0.0'):\n",
    "    pil.ANTIALIAS=pil.LANCZOS\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ef00983-575e-42f1-a591-e6eb4ff424db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.reset_default_graph()\n",
    "# convnet = layers.Input(shape=(50, 50, 1))\n",
    "# convnet = layers.Conv2D(32, 5, activation= 'relu')(convnet)\n",
    "# convnet = layers.MaxPooling2D(5)(convnet)\n",
    "# convnet = layers.Conv2D(64, 5, activation= 'relu')(convnet)\n",
    "# convnet = layers.MaxPooling2D(5)(convnet)\n",
    "# convnet = layers.Conv2D(128, 5, activation= 'relu')(convnet)\n",
    "# convnet = layers.MaxPooling2D(5)(convnet)\n",
    "# convnet = layers.Conv2D(64, 5, activation= 'relu')(convnet)\n",
    "# convnet = layers.MaxPooling2D(5)(convnet)\n",
    "# convnet = layers.Conv2D(32, 5, activation= 'relu')(convnet)\n",
    "# convnet = layers.MaxPooling2D(5)(convnet)\n",
    "\n",
    "# convnet = tf.contrib.layers.fully_connected(convnet, 1024, activation_fn = 'relu')\n",
    "# convnet = layers.Dropout(0.8)(convnet)\n",
    "# convnet = tf.contrib.layers.fullyconnected(convnet, 3, activation_fn = 'softmax')\n",
    "# convnet = tf.keras.models.Sequencial(optimizer='adam',learning_rate=0.001, loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d762d25a-b9c2-4650-b99b-02847b99d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: FRS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 100\n",
      "Validation samples: 100\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 50, 50, 1) for Tensor TargetsData/Y:0, which has shape (?, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m convnet \u001b[38;5;241m=\u001b[39m regression(convnet, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m tflearn\u001b[38;5;241m.\u001b[39mDNN(convnet, tensorboard_verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshow_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFRS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\tflearn\\models\\dnn.py:196\u001b[0m, in \u001b[0;36mDNN.fit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Retrieve data preprocesing and augmentation\u001b[39;00m\n\u001b[0;32m    195\u001b[0m daug_dict, dprep_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_data_preprocessing_and_augmentation()\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_feed_dicts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_feed_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mshow_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msnapshot_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msnapshot_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mshuffle_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdprep_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdprep_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdaug_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdaug_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mexcl_trainops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexcl_trainops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\tflearn\\helpers\\trainer.py:341\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, train_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ops):\n\u001b[0;32m    339\u001b[0m     caller\u001b[38;5;241m.\u001b[39mon_sub_batch_begin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_state)\n\u001b[1;32m--> 341\u001b[0m     snapshot \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m                               \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_checkpoint_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msnapshot_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msnapshot_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mshow_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# Update training state\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_state\u001b[38;5;241m.\u001b[39mupdate(train_op, train_ops_count)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\tflearn\\helpers\\trainer.py:827\u001b[0m, in \u001b[0;36mTrainOp._train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    825\u001b[0m feed_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dflow\u001b[38;5;241m.\u001b[39mnext()\n\u001b[0;32m    826\u001b[0m tflearn\u001b[38;5;241m.\u001b[39mis_training(\u001b[38;5;28;01mTrue\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n\u001b[1;32m--> 827\u001b[0m _, train_summ_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msumm_op\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mfeed_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# Retrieve loss value from summary string\u001b[39;00m\n\u001b[0;32m    831\u001b[0m sname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope_name\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1189\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1185\u001b[0m   np_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(subfeed_val, dtype\u001b[38;5;241m=\u001b[39msubfeed_dtype)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_tensor_handle_feed \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m subfeed_t\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mis_compatible_with(np_val\u001b[38;5;241m.\u001b[39mshape)):\n\u001b[1;32m-> 1189\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1190\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot feed value of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(np_val\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for Tensor \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1191\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfeed_t\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which has shape \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1192\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(subfeed_t\u001b[38;5;241m.\u001b[39mget_shape())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_feedable(subfeed_t):\n\u001b[0;32m   1194\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfeed_t\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m may not be fed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (64, 50, 50, 1) for Tensor TargetsData/Y:0, which has shape (?, 3)"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "convnet = input_data(shape=[50, 50, 1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation= 'relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam',learning_rate=0.001, loss=\"categorical_crossentropy\")\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test),show_metric = True, run_id= \"FRS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c5d18-6840-49f7-877e-7721986cc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"visualization\")):\n",
    "        path = os.path.join(\"visualization\", img)\n",
    "        img_num = img.split('.')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d1df4-88a2-4565-9e29-ece72598be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # installation command: pip install matplotlib\n",
    " \n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(50,50,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "     \n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'Bharat'\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'Shyam'\n",
    "    else:\n",
    "        my_label = 'Khedup'\n",
    "         \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "     \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ee643-b951-4822-8e6f-88bca4ec4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame from webcam.\")\n",
    "        break\n",
    "    data = frame.reshape(\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # name = input(\"Enter your name: \")\n",
    "    # workbook = xlsxwriter.Workbook(f\"{name}.xlsx\")\n",
    "    # worksheet = workbook.add_worksheet()\n",
    "    \n",
    "    # if flag:\n",
    "    #     worksheet.write('Bharat', 'Present')\n",
    "    # else:\n",
    "    #     worksheet.write('Bharat', \"Absent\")\n",
    "    # workbook.close()\n",
    "    # print(\"Done\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9a7dc-de0c-40c9-8511-966d848edba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7770e-5f6b-4afe-83b7-e8f0c1f478e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bee74-076e-438b-a3ab-2b2a2f31cc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf27507-a6c1-42f3-bacd-352deeb2539c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
