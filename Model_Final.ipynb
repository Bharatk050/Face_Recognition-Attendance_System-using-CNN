{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92db7460-a043-45ac-9e14-af33e41698a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\tflearn\\__init__.py:5: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from PIL import Image as pil\n",
    "from pkg_resources import parse_version\n",
    "\n",
    "if parse_version(pil.__version__)>=parse_version('10.0.0'):\n",
    "    pil.ANTIALIAS=pil.LANCZOS\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8744a-4437-4df3-aa06-d73ede9cdc92",
   "metadata": {},
   "source": [
    "# Face Detection and Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9140c08d-fb6b-4ced-a79e-25172f598ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    detector = MTCNN()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    id = 2\n",
    "    name = \"Anurag\"\n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame from webcam.\")\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        input_faces = detector.detect_faces(rgb_frame)\n",
    "    \n",
    "        for face in input_faces:\n",
    "            x, y, width, height = face['box']\n",
    "            cropped_face = gray[y:y+height, x:x+width]\n",
    "            img_id += 1\n",
    "            face = cv2.resize(cropped_face, (200, 200))\n",
    "            \n",
    "            file_name_path = f\"DataSet/{name}\" + \".\" + str(id) + \".\"+ str(img_id) + \".jpg\"\n",
    "            # file_name_path = f\"visualization/{name}\" + \".\" + str(id) + \".\"+ str(img_id) + \".jpg\"\n",
    "            \n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Face\", face)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"DataSet Successfully Generated\")\n",
    "# generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bf0b4-c5cd-4bd6-8af7-743928a63a44",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5d491a-82bf-4002-ac2a-4bfb1d5b32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label(image_name):\n",
    "    name = image_name.split('.')[0]\n",
    "    if name == \"Bharat\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name == \"Anurag\":\n",
    "        return np.array([0,1,0])\n",
    "    elif name == \"Pawan\":\n",
    "        return np.array([0,0,1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019e07a2-df2c-40ee-84d7-04f391c9506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:04<00:00, 659.99it/s]\n"
     ]
    }
   ],
   "source": [
    "def my_data():\n",
    "    data= []\n",
    "    for img in tqdm(os.listdir(\"DataSet\")):\n",
    "        path = os.path.join(\"DataSet\", img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50, 50))\n",
    "        data.append([np.array(img_data), my_label(img)])\n",
    "    shuffle(data)\n",
    "    return data\n",
    "data = my_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600a994-00ba-48ac-954d-8694ec09ffb1",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cd79c7-0f18-4944-8abf-88e7c78b3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:02<00:00, 1148.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 50, 50, 1)\n",
      "(600, 50, 50, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = my_data()\n",
    "train = data[:2400]\n",
    "test = data[2400:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
    "y_train = np.array([i[1] for i in train])\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
    "y_test = np.array([i[1] for i in test])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4ae3d3-ba06-4f2c-823b-e8f1dab9806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train: print(np.argmax(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e72bc-3b51-4189-b8b3-1a0831b1528d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d762d25a-b9c2-4650-b99b-02847b99d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "def build_model(img_aug):\n",
    "    convnet = input_data(shape=[50, 50, 1], data_augmentation=img_aug)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 32, 5, activation= 'relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    convnet = dropout(convnet, 0.5) \n",
    "    \n",
    "    convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "    \n",
    "    convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "    convnet = batch_normalization(convnet)\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "    \n",
    "    convnet = fully_connected(convnet, 3, activation='softmax')\n",
    "    \n",
    "    convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34ce2b0-30e6-4bdd-94a0-b348d68cb42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1329  | total loss: \u001b[1m\u001b[32m0.16805\u001b[0m\u001b[0m | time: 6.568s\n",
      "| Adam | epoch: 035 | loss: 0.16805 - acc: 0.9497 -- iter: 2368/2400\n",
      "Training Step: 1330  | total loss: \u001b[1m\u001b[32m0.17997\u001b[0m\u001b[0m | time: 7.744s\n",
      "| Adam | epoch: 035 | loss: 0.17997 - acc: 0.9470 | val_loss: 0.01196 - val_acc: 0.9983 -- iter: 2400/2400\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Image Augmentation Settings\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_flip_updown()\n",
    "img_aug.add_random_rotation(max_angle=25.)\n",
    "img_aug.add_random_blur(sigma_max=3.)\n",
    "\n",
    "model = build_model(img_aug=img_aug)\n",
    "model.fit(X_train, y_train, n_epoch=35, validation_set=(X_test, y_test), show_metric = True, run_id=\"Train\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e067c1-d2d3-4993-a076-4a8d3070e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aaa1ee-a95b-4aca-82b7-353d59ec0274",
   "metadata": {},
   "source": [
    "# Feature Engineering for Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82c5d18-6840-49f7-877e-7721986cc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Image Processing\n",
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"visualization\")):\n",
    "        path = os.path.join(\"visualization\", img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efea11ef-1815-4856-99c9-07fc9619bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vdata = data_for_visualization()\n",
    "# for i in Vdata:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a42c29a-37d6-4397-85c4-87a30b73b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def attendance_update(file_path, name, user_name):\n",
    "    status = None\n",
    "    if user_name == name:\n",
    "        status = 'Present'\n",
    "    else:\n",
    "        status = 'Absent'\n",
    "    \n",
    "    today = date.today()\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active \n",
    "    # Update a cell value\n",
    "    sheet['A1'] = f'{name}'\n",
    "    sheet['B1'] = status\n",
    "    sheet['C1'] = today\n",
    "    workbook.save(file_path)\n",
    "    print('Updated Excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6d1df4-88a2-4565-9e29-ece72598be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1031.81it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Pawan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Excel\n",
      "['Bharat']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vdata = data_for_visualization()\n",
    "\n",
    "file_path = 'Attendance_Log.xlsx'\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "\n",
    "for data in Vdata:\n",
    "    user_name = input(\"Enter your name: \")\n",
    "    img_data = data[0]\n",
    "    new_data = img_data.reshape(50,50,1)\n",
    "    prediction = model.predict([new_data])[0]\n",
    "    # print(prediction)\n",
    "\n",
    "    if np.argmax(prediction) == 0:\n",
    "        name = 'Bharat'\n",
    "    elif np.argmax(prediction) == 1:\n",
    "        name = 'Anurag'\n",
    "    else:\n",
    "        name = 'Pawan'\n",
    "        \n",
    "    attendance_update(file_path, name, user_name)\n",
    "    lst = []\n",
    "    lst.append(name)\n",
    "    print(lst)\n",
    "\n",
    "    plt.imshow(img_data, cmap= 'gray')\n",
    "    plt.title(name)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb0b6c34-ea20-40ec-84df-e185bf159dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\91798\\OneDrive\\Desktop\\In-House\\Model.keras is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decaa393-9b25-4d0e-b93c-363f53779fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:635: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Python\\Lib\\site-packages\\keras\\src\\engine\\training_utils_v1.py:50: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 54\u001b[0m\n\u001b[0;32m     46\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03mNeed to aad a key to terminate the process.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mNeed to aad key to take a screenshot and save it to the desired file location.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mvalidation_screenshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 26\u001b[0m, in \u001b[0;36mvalidation_screenshot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     28\u001b[0m     x, y, w, h \u001b[38;5;241m=\u001b[39m face[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\mtcnn\\mtcnn.py:300\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# We pipe here each of the stages\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[1;32m--> 300\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m [total_boxes, points] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    304\u001b[0m bounding_boxes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\mtcnn\\mtcnn.py:337\u001b[0m, in \u001b[0;36mMTCNN.__stage1\u001b[1;34m(self, image, scales, stage_status)\u001b[0m\n\u001b[0;32m    334\u001b[0m status \u001b[38;5;241m=\u001b[39m stage_status\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m scales:\n\u001b[1;32m--> 337\u001b[0m     scaled_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__scale_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     img_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(scaled_image, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    340\u001b[0m     img_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(img_x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32mD:\\Python\\Lib\\site-packages\\mtcnn\\mtcnn.py:124\u001b[0m, in \u001b[0;36mMTCNN.__scale_image\u001b[1;34m(image, scale)\u001b[0m\n\u001b[0;32m    121\u001b[0m width_scaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(width \u001b[38;5;241m*\u001b[39m scale))\n\u001b[0;32m    122\u001b[0m height_scaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(height \u001b[38;5;241m*\u001b[39m scale))\n\u001b[1;32m--> 124\u001b[0m im_data \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_AREA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Normalize the image's pixels\u001b[39;00m\n\u001b[0;32m    127\u001b[0m im_data_normalized \u001b[38;5;241m=\u001b[39m (im_data \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.0078125\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def validation_screenshot():\n",
    "    Vdata = data_for_visualization()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = MTCNN()\n",
    "    id = 1\n",
    "    img_id = 0\n",
    "    file_name = \"Stranger\"\n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        for data in Vdata:\n",
    "            img_data = data[0]\n",
    "            new_data = img_data.reshape(50,50,1)\n",
    "            prediction = model.predict([new_data])[0]\n",
    "        \n",
    "            if np.argmax(prediction) == 0:\n",
    "                name = 'Bharat'\n",
    "            elif np.argmax(prediction) == 1:\n",
    "                name = 'Shyam'\n",
    "            else:\n",
    "                name = 'Pawan'\n",
    "             \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector.detect_faces(frame_rgb)\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            image = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(image, (200, 200))\n",
    "            # cv2.putText(frame, name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        \n",
    "            cv2.imshow(\"Recognition\", frame)\n",
    "            \n",
    "            \n",
    "            if cv2.waitKey(1) == ord('v'):\n",
    "                img_id+=1\n",
    "                file_name_path = f\"visualization/{file_name}\" + \".\" + str(id) + \".\"+ str(img_id) + \".jpg\"\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Need to aad a key to terminate the process.\n",
    "Need to aad key to take a screenshot and save it to the desired file location.\n",
    "\"\"\"\n",
    "\n",
    "# validation_screenshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7903280-0490-47f5-b4e1-d0edfd40e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c48387-d80e-43a8-9e4e-9427c3b6907f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
